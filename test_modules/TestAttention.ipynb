{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the details can be found in the following paper (attention is all you need)\n",
    "\n",
    "https://arxiv.org/pdf/1612.08083.pdf\n",
    "\n",
    "Scaled Dot-Product Attention (section 3.2 , 3.2.1)\n",
    "\n",
    "https://ricardokleinklein.github.io/2017/11/16/Attention-is-all-you-need.html\n",
    "\n",
    "https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.WxTBn-6FPcc\n",
    "\n",
    "\n",
    "\n",
    "In terms of encoder-decoder, the query is usually the hidden state of the decoder. Whereas key, is the hidden state of the encoder, and the corresponding value is normalized weight, representing how much attention a key gets. Output is calculated as a wighted sum â€“ here the dot product of query and key is used to get a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray} Attention (Q,K,V) = softmax \\Big( \\frac{QK^T}{\\sqrt{d_k}} \\Big) V \\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "V=tf.get_variable(name=\"values\",shape=[1, 4, 256],initializer=tf.truncated_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keys\n",
    "K=tf.get_variable(name=\"keys\",shape=[1, 4, 256],initializer=tf.truncated_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=tf.get_variable(name=\"query\",shape=[1, 314, 256],initializer=tf.truncated_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "sys.path.append('../network')\n",
    "from attention import attention\n",
    "from hp import HP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_12:0' shape=(1, 314, 512) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(K,V,Q,HP.d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

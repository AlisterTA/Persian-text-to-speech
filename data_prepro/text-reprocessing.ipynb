{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "lines=[]\n",
    "lines_text_only=[]\n",
    "import re\n",
    "data_dir=\"F:/persian speech data/NEWDATA/DATA\"\n",
    "with open(\"F:/persian speech data/NEWDATA/DATA/metadata.csv\", \"r\",encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        path,text=line.split('|')\n",
    "        #remove multiple spaces in the line\n",
    "        #text=text.replace(\"«\",\" \").replace(\"»\",\" \").replace(\"(\",\" \").replace(\")\",\" \").replace(\"-\",\" \").replace(\"ـ\",\" \").replace(\"؛\",\"،\").lower()\n",
    "        #chars = set('0123456789۱۲۳۴۵۶۷۸۹+abcdefghijklmnopqwzyxَُِّْٓٔ')\n",
    "        #if any((c in chars) for c in text):\n",
    "        #    print('Found')\n",
    "        #else:\n",
    "        #    text=\" \".join(text.split())\n",
    "        #    lines.append(path+'|'+text)\n",
    "        #    lines_text_only.append(text)\n",
    "        #else:\n",
    "            #print(numbers)\n",
    "        lines_text_only.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '.', ':', '،', '؟', 'ء', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ً', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی']\n"
     ]
    }
   ],
   "source": [
    "get_character_set = set()\n",
    "for sentence in lines_text_only:\n",
    "    for char in sentence:\n",
    "        get_character_set.add(char)\n",
    "        \n",
    "vocabList = sorted([c for c in get_character_set])\n",
    "print(vocabList)\n",
    "vocabString = \"\".join(vocabList)\n",
    "with open(os.path.join(data_dir,'persian_chars.txt'),'w',encoding='utf-8') as f:\n",
    "    f.write(vocabString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n']\n",
      "[' ', '!', '.', ':', '،', '؟', 'ء', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ً', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی']\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "with open(os.path.join(data_dir,'persian_chars.txt'),'r',encoding='utf-8') as f:\n",
    "    for sentence in f:\n",
    "        vocabList = sorted([c for c in sentence])\n",
    "        print(vocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
